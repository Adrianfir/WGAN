{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9430c18a",
   "metadata": {},
   "source": [
    "# WGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5d57a",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d3f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Flatten, Dense, Reshape, Dropout, Input, BatchNormalization, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.datasets import fashion_mnist as mnist \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc1ee8",
   "metadata": {},
   "source": [
    "## Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d75525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Input_Data():\n",
    "    \n",
    "    (Xtrain,_) , (_,_) = mnist.load_data()\n",
    "\n",
    "    #     Xtrain = (Xtrain.astype('float32')/127.50) - 1\n",
    "#     Scaler = StandardScaler()\n",
    "\n",
    "#     Xtrain_shape = Xtrain.shape\n",
    "\n",
    "#     Xtrain = pd.DataFrame(Xtrain.reshape(Xtrain_shape[0],-1))\n",
    "#     Xtrain = Scaler.fit_transform(Xtrain)\n",
    "#     Xtrain = np.array(Xtrain)\n",
    "#     Xtrain = np.reshape(Xtrain,[Xtrain_shape[0],Xtrain_shape[1],Xtrain_shape[2]])\n",
    "    Xtrain = Xtrain.astype('float32')\n",
    "    Xtrain = (Xtrain-127.5)/127.5\n",
    "    Xtrain = Xtrain[...,np.newaxis]\n",
    "    \n",
    "    \n",
    "    return Xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c756e83",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce140ab",
   "metadata": {},
   "source": [
    "### Generative Network - Discriminative Network - GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clip_limit(Constraint):\n",
    "\n",
    "    def __init__(self, clip_value):\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return backend.clip(weights, -self.clip_value, self.clip_value)\n",
    " \n",
    "\n",
    "    def get_config(self):\n",
    "        return {'clip_value': self.clip_value}\n",
    "        \n",
    "        \n",
    "class GAN:   \n",
    "    \n",
    "    ### Generative Network\n",
    "    def build_Gen(self,z_dim):\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "        \n",
    "        self.Gen = Sequential()\n",
    "    \n",
    "        self.Gen.add(Dense(256*7*7,input_dim=z_dim, kernel_initializer=init))\n",
    "        self.Gen.add(LeakyReLU(0.2))\n",
    "        self.Gen.add(Reshape((7,7,256)))\n",
    "        \n",
    "        self.Gen.add(Conv2DTranspose(256,kernel_size=4,strides=2, padding='same',kernel_initializer=init))\n",
    "        self.Gen.add(BatchNormalization())\n",
    "        self.Gen.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        self.Gen.add(Conv2DTranspose(256,kernel_size=4, strides=2, padding='same',kernel_initializer=init))\n",
    "        self.Gen.add(BatchNormalization())\n",
    "        self.Gen.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        self.Gen.add(Conv2D(1,kernel_size=7,strides=1, padding='same', activation = 'tanh',\\\n",
    "                                     kernel_initializer=init))\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    ### Discriminative Network\n",
    "    def build_Dis(self,data_size):\n",
    "        \n",
    "        init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "        \n",
    "        self.Dis = Sequential()\n",
    "        \n",
    "        self.Dis.add(Conv2D(64, kernel_size = 4, strides=2, input_shape = data_size, padding = 'same',kernel_initializer=init, kernel_constraint=Clip_limit(0.01)))\n",
    "        self.Dis.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        self.Dis.add(Conv2D(64, kernel_size = 4, strides=2, padding = 'same', kernel_initializer=init, kernel_constraint=Clip_limit(0.01)))\n",
    "        self.Dis.add(BatchNormalization())\n",
    "        self.Dis.add(LeakyReLU(alpha = 0.2))   \n",
    "\n",
    "#         self.Dis.add(Conv2D(64, kernel_size = 4, strides=1, padding = 'same', kernel_initializer=init, kernel_constraint=Clip_limit(0.01)))\n",
    "#         self.Dis.add(BatchNormalization())\n",
    "#         self.Dis.add(LeakyReLU(alpha = 0.2)) \n",
    "        \n",
    "        self.Dis.add(Flatten())\n",
    "        \n",
    "        self.Dis.add(Dense(1))\n",
    "#         self.Dis.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    ### GAN Network\n",
    "    def build_GAN(self):\n",
    "        self.GAN = Sequential()\n",
    "    \n",
    "        self.GAN.add(self.Gen)\n",
    "        self.GAN.add(self.Dis)\n",
    "    \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d6bc3",
   "metadata": {},
   "source": [
    "## Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d5d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_results(model,z_dim):\n",
    "    \n",
    "    z = np.random.normal(0, 1, (16, z_dim))\n",
    "    gen_imgs = model.Gen.predict(z)\n",
    "    gen_imgs = 0.5*gen_imgs + 0.5\n",
    "\n",
    "    fig,axs = plt.subplots(4,4,figsize=(4,4),sharey=True,sharex=True)\n",
    "\n",
    "    cnt=0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            axs[i, j].imshow(gen_imgs[cnt,:,:,0],cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt+=1\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cce223",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff75f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(batch_size, Xtrain, z_dim, Info, Iters, Interval):\n",
    "    \n",
    "    Real_ideal = np.ones((batch_size,1))\n",
    "    Fake_ideal = -np.ones((batch_size,1))\n",
    "    \n",
    "    for Iter in range(Iters):\n",
    "        ## Discrimintive Network Training\n",
    "\n",
    "        Dis_loss_R, Dis_loss_F = list(),list()\n",
    "        for k in range(5):\n",
    "                 \n",
    "            Xtrain_sample = Xtrain[np.random.randint(0,Xtrain.shape[0],batch_size)]\n",
    "            Z = np.random.normal(0,1,(batch_size,z_dim)) \n",
    "            Fake_Data_by_GenerativeNet = model.Gen.predict(Z)\n",
    "\n",
    "            \n",
    "            Dis_loss_R.append(model.Dis.train_on_batch(Xtrain_sample,Real_ideal))\n",
    "            Dis_loss_F.append(model.Dis.train_on_batch(Fake_Data_by_GenerativeNet,Fake_ideal))\n",
    "        \n",
    "        Dis_loss = 0.5*(np.mean(Dis_loss_R) + np.mean(Dis_loss_F))\n",
    "        \n",
    "        ## Generative Network Training\n",
    "        Z = np.random.normal(0,1,(batch_size,z_dim))\n",
    "        Gen_loss = model.GAN.train_on_batch(Z,Fake_ideal)\n",
    "        \n",
    "        if (Iter+1) % Interval == 0:\n",
    "            Info.losses.append((Dis_loss,Gen_loss))\n",
    "#             Info.accuracies.append(np.multiply(100,Dis_accuracy))\n",
    "            Info.iteration_checks.append(Iter+1)\n",
    "            \n",
    "            print(\"%d [Dis_loss: %f] [Gen_loss: %f]\" %\n",
    "                  (Iter+1,Dis_loss,Gen_loss))            \n",
    "            \n",
    "            show_results(model,z_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91d4bc",
   "metadata": {},
   "source": [
    "## Wasserstein Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68beb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wasserstein_loss (y_True, y_Pred):\n",
    "    return backend.mean(y_True*y_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b115020",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c4783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 [Dis_loss: -8.321337] [Gen_loss: -2.448926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_1036\\1327190538.py:16: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 [Dis_loss: -19.357517] [Gen_loss: -21.399738]\n",
      "60 [Dis_loss: -31.155238] [Gen_loss: -38.896187]\n",
      "80 [Dis_loss: -42.536981] [Gen_loss: -49.033375]\n",
      "100 [Dis_loss: -53.387807] [Gen_loss: -59.515022]\n",
      "120 [Dis_loss: -65.230370] [Gen_loss: -66.786377]\n"
     ]
    }
   ],
   "source": [
    "class info:\n",
    "    \n",
    "    def __init__(self,losses=[],iteration_checks=[]):\n",
    "        \n",
    "        self.losses = losses\n",
    "        self.iteration_checks = iteration_checks\n",
    "        \n",
    "Xtrain = Input_Data()\n",
    "data_size = Xtrain.shape[1:]\n",
    "batch_size = 64\n",
    "z_dim = 50\n",
    "\n",
    "model  = GAN()\n",
    "model.summary()\n",
    "\n",
    "model.build_Dis(data_size)\n",
    "# Dis_opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2 = 0.999)\n",
    "Dis_opt = RMSprop(lr=0.00005) \n",
    "model.Dis.compile (loss = Wasserstein_loss,\n",
    "               optimizer = Dis_opt)\n",
    "\n",
    "model.build_Gen(z_dim)\n",
    "# model.Gen.compile(loss = 'binary_crossentropy',\n",
    "#                optimizer = Adam())\n",
    "\n",
    "model.Dis.trainable = False\n",
    "# for layer in model.Dis.layers:\n",
    "#     if not isinstance(layer, BatchNormalization):\n",
    "#         layer.trainable = False\n",
    "            \n",
    "model.build_GAN()\n",
    "GAN_opt = RMSprop(lr=0.00005)\n",
    "# GAN_opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2 = 0.999)\n",
    "model.GAN.compile(loss = Wasserstein_loss,\n",
    "              optimizer = GAN_opt)\n",
    "\n",
    "    \n",
    "Info = info([],[])\n",
    "Train(batch_size, Xtrain, z_dim, Info, Iters = 1000, Interval = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c3acd",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Info.iteration_checks,Info.losses)\n",
    "\n",
    "plt.title('loss vs. epochs')\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['Dis_loss','Gen_loss'], loc='upper right')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
